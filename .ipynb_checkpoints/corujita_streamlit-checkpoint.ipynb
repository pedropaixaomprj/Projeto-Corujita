{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42659ddc-3d27-408a-afca-7869257441c1",
   "metadata": {},
   "source": [
    "# Projeto Corujita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784c2b1-9433-4e14-8c90-4ce0462e8bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "\n",
    "# Import necessary modules to load FAISS index\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.base import VectorStoreRetriever\n",
    "\n",
    "# --- Load API key from environment file ---\n",
    "load_dotenv(Path(\"config.env\"))\n",
    "DEEPSEEK_API_KEY = os.environ.get(\"DEEPSEEK_API_KEY\")\n",
    "if not DEEPSEEK_API_KEY:\n",
    "    raise ValueError(\"DEEPSEEK_API_KEY not found. Please set it in your environment variables.\")\n",
    "\n",
    "# --- API call function ---\n",
    "def call_deepseek_api(api_key, input_text):\n",
    "    url = \"https://api.deepseek.com/v1/chat/completions\"  # Adjust if necessary\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"deepseek-chat\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": input_text}]\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    response.raise_for_status()  # Raise error if request failed\n",
    "    data = response.json()\n",
    "    return data[\"choices\"][0][\"message\"][\"content\"] if \"choices\" in data else None\n",
    "\n",
    "# --- Query expansion functions ---\n",
    "def generate_expanded_query(original_query):\n",
    "    prompt = f\"\"\"\n",
    "    Dado o contexto de um assistente virtual para o sistema Nova SAT do Ministério Público do Estado do Rio de Janeiro (MPRJ), \n",
    "    Expanda a seguinte pergunta do usuário gerando 10 sinônimos, reformulações e variações que poderiam ter sido feitas por outros usuários no passado. \n",
    "    \n",
    "    O objetivo é melhorar a recuperação da resposta correta, garantindo que perguntas semelhantes sejam identificadas como equivalentes. \n",
    "    Priorize termos técnicos e expressões usadas no contexto jurídico e administrativo do MPRJ.\n",
    "    \n",
    "    Pergunta original: \"{original_query}\"\n",
    "    \n",
    "    Exemplo de query: \"Estou com problema no login\".\n",
    "    Exemplo de resposta (resumido): \"Estou com problema no login. Não consigo logar na página. Não consigo entrar na nova SAT. (...) O que fazer quando o login está bugado?.\n",
    "    \n",
    "    Responda apenas com as expressões-sinônimos, separadas por ponto. Não acrescente nada mais além disso. Não acrescente números indicadores da lista.\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "def expand_query_with_llm(api_key, original_query):\n",
    "    prompt = generate_expanded_query(original_query)\n",
    "    response = call_deepseek_api(api_key, prompt)\n",
    "    expanded_terms = response.split(',')\n",
    "    return [term.strip() for term in expanded_terms]\n",
    "\n",
    "                             \n",
    "with open(\"vectorstore.pkl\", \"rb\") as f:\n",
    "    vectorstore = pickle.load(f)\n",
    "    retriever = VectorStoreRetriever(vectorstore=vectorstore)\n",
    "    \n",
    "# --- Document retrieval function ---\n",
    "def retrieve_documents(api_key, original_query, retriever, expand=False):\n",
    "    if expand:\n",
    "        expanded_terms = expand_query_with_llm(api_key, original_query)\n",
    "        final_query = '. '.join([original_query] + expanded_terms)\n",
    "        st.write(\"Consulta modificada:\", final_query)\n",
    "    else:\n",
    "        final_query = original_query\n",
    "        \n",
    "    relevant_documents = retriever.get_relevant_documents(final_query)\n",
    "    return relevant_documents\n",
    "\n",
    "# --- Streamlit Chatbot Interface ---\n",
    "def main():\n",
    "    st.title(\"Chatbot Assistente - Nova SAT\")\n",
    "    \n",
    "    # Initialize chat history in session_state if not already present\n",
    "    if \"chat_history\" not in st.session_state:\n",
    "        st.session_state.chat_history = []\n",
    "        # Initial greeting message in Portuguese\n",
    "        st.session_state.chat_history.append({\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": \"Olá! Em que posso ajudar? Você tem alguma pergunta?\"\n",
    "        })\n",
    "    \n",
    "    # Display chat history\n",
    "    for message in st.session_state.chat_history:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            st.markdown(f\"**Chatbot:** {message['content']}\")\n",
    "        else:\n",
    "            st.markdown(f\"**Você:** {message['content']}\")\n",
    "    \n",
    "    # Input field for user's question\n",
    "    user_input = st.text_input(\"Digite sua pergunta:\", key=\"user_input\")\n",
    "    \n",
    "    # Process the input when the \"Enviar\" button is clicked\n",
    "    if st.button(\"Enviar\") and user_input:\n",
    "        # Append user's question to chat history\n",
    "        st.session_state.chat_history.append({\n",
    "            \"role\": \"user\", \n",
    "            \"content\": user_input\n",
    "        })\n",
    "        \n",
    "        # Retrieve relevant documents using the new FAISS retriever\n",
    "        docs = retrieve_documents(DEEPSEEK_API_KEY, user_input, retriever, expand=False)\n",
    "        \n",
    "        # Build the response message based on the retrieved document\n",
    "        if docs:\n",
    "            doc = docs[0]\n",
    "            if 'Resposta' in doc.metadata:\n",
    "                response_message = f\"{doc.metadata['Resposta']}\\n\\n\"\n",
    "            else:\n",
    "                response_message = f\"Pergunta encontrada: {doc.page_content}\\n\\n\"\n",
    "        else:\n",
    "            response_message = \"Nenhuma mensagem encontrada.\"\n",
    "            \n",
    "        # Append chatbot's answer to chat history\n",
    "        st.session_state.chat_history.append({\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": response_message\n",
    "        })\n",
    "        st.rerun()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
