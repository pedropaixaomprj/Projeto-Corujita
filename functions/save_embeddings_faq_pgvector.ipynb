{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6aa630e-fdcf-42e4-9670-f03d5f9d600b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9418cbde-426e-4cc6-96f8-fb0603128537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "from typing import List, Optional, Tuple\n",
    "import requests\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # loads .env from project root\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae3b0a-5176-4fc4-b410-7eda5abc4de0",
   "metadata": {},
   "source": [
    "# Config initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1d5328b3-6dc0-4db5-a027-d4dc30247a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "EXCEL_PATH = \"../Data/FAQ_Atualizado.xlsx\"\n",
    "SHEET_NAME = 0  # or a sheet name\n",
    "\n",
    "EMBED_URL = \"https://go-llm.mprj.mp.br/st/embed\"\n",
    "HEADERS = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json;charset=UTF-8\",\n",
    "    \"Accept-Encoding\": \"gzip,deflate\",\n",
    "}\n",
    "\n",
    "SCHEMA_NAME = \"nlp\"\n",
    "TABLE_NAME = \"faq_embeddings\"   # change if you want\n",
    "DB_BATCH_SIZE = 500             # insert batch size\n",
    "REQUEST_TIMEOUT = 60\n",
    "RETRY_MAX = 3\n",
    "RETRY_BACKOFF = 1.5  # exponential\n",
    "\n",
    "# DB\n",
    "PGHOST = os.getenv(\"PGHOST\")\n",
    "PGDATABASE = os.getenv(\"PGDATABASE\")\n",
    "PGUSER = os.getenv(\"PGUSER\")\n",
    "PGPASSWORD = os.getenv(\"PGPASSWORD\")\n",
    "PGPORT = os.getenv(\"PGPORT\", \"5432\")\n",
    "\n",
    "# Optional cert env vars\n",
    "os.environ[\"CURL_CA_BUNDLE\"] = os.getenv(\"CURL_CA_BUNDLE\", \"\")\n",
    "os.environ[\"REQUESTS_CA_BUNDLE\"] = os.getenv(\"REQUESTS_CA_BUNDLE\", \"\")\n",
    "\n",
    "# Table & index config\n",
    "TABLE_NAME = os.getenv(\"PGVECTOR_TABLE\", \"faq_embeddings\")\n",
    "DISTANCE = os.getenv(\"PGVECTOR_DISTANCE\", \"cosine\").lower()  # l2|cosine|ip\n",
    "INDEX_TYPE = os.getenv(\"PGVECTOR_INDEX_TYPE\", \"ivfflat\").lower()  # ivfflat|hnsw\n",
    "IVF_LISTS = int(os.getenv(\"PGVECTOR_IVFFLAT_LISTS\", \"200\"))\n",
    "HNSW_M = int(os.getenv(\"PGVECTOR_HNSW_M\", \"16\"))\n",
    "HNSW_EF_CONSTRUCTION = int(os.getenv(\"PGVECTOR_HNSW_EF_CONSTRUCTION\", \"200\"))\n",
    "HNSW_EF_SEARCH = int(os.getenv(\"PGVECTOR_EF_SEARCH\", \"64\"))\n",
    "ANALYZE_AFTER_LOAD = os.getenv(\"PGVECTOR_ANALYZE_AFTER_LOAD\", \"true\").lower() == \"true\"\n",
    "\n",
    "# Embedding API\n",
    "EMBED_URL = os.getenv(\"EMBED_URL\")\n",
    "EMBED_HEADERS = {\n",
    "    \"Accept\": os.getenv(\"EMBED_ACCEPT\", \"application/json\"),\n",
    "    \"Content-Type\": os.getenv(\"EMBED_CONTENT_TYPE\", \"application/json;charset=UTF-8\"),\n",
    "    \"Accept-Encoding\": os.getenv(\"EMBED_ACCEPT_ENCODING\", \"gzip,deflate\"),\n",
    "}\n",
    "EMBED_TIMEOUT = int(os.getenv(\"EMBED_REQUEST_TIMEOUT\", \"60\"))\n",
    "EMBED_RETRY_MAX = int(os.getenv(\"EMBED_RETRY_MAX\", \"3\"))\n",
    "EMBED_RETRY_BACKOFF = float(os.getenv(\"EMBED_RETRY_BACKOFF\", \"1.5\"))\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=PGHOST, \n",
    "    database=PGDATABASE, \n",
    "    user=PGUSER, \n",
    "    password=PGPASSWORD, \n",
    "    port=PGPORT\n",
    ")\n",
    "\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0c776-bb47-4626-b95d-856b59ce4da7",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dbfb62eb-9d2c-43a9-8ff0-7e98d43330cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def fetch_embedding(text: str, session: Optional[requests.Session] = None) -> List[float]:\n",
    "    \"\"\"\n",
    "    Calls the server with {\"text\": \"...\"} and expects a JSON array as response.\n",
    "    Retries on failure with exponential backoff.\n",
    "    \"\"\"\n",
    "    if session is None:\n",
    "        session = requests.Session()\n",
    "\n",
    "    payload = {\"text\": text}\n",
    "    last_err = None\n",
    "    for attempt in range(RETRY_MAX):\n",
    "        try:\n",
    "            r = session.post(\n",
    "                EMBED_URL,\n",
    "                headers=HEADERS,\n",
    "                data=json.dumps(payload),\n",
    "                timeout=REQUEST_TIMEOUT\n",
    "            )\n",
    "            # 422 happens if body isn't exactly as API wants; we now match it.\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if not isinstance(data, list):\n",
    "                raise ValueError(f\"Unexpected response type (expected list): {type(data)}\")\n",
    "            # Ensure it's a list[float]\n",
    "            emb = [float(x) for x in data]\n",
    "            return emb\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            # backoff except on last try\n",
    "            if attempt < RETRY_MAX - 1:\n",
    "                time.sleep(RETRY_BACKOFF ** (attempt + 1))\n",
    "    raise RuntimeError(f\"Failed to get embedding after retries. Last error: {last_err}\")\n",
    "\n",
    "def ensure_pgvector_extension_and_table(embedding_dim: int):\n",
    "    cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "    cursor.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {SCHEMA_NAME}.{TABLE_NAME} (\n",
    "            pergunta_ID           BIGINT,\n",
    "            pergunta_var_ID        BIGINT,\n",
    "            pergunta             TEXT,\n",
    "            resposta             TEXT,\n",
    "            ultima_atualizacao    TIMESTAMP NULL,\n",
    "            embedding_st         vector({embedding_dim}),\n",
    "            PRIMARY KEY (pergunta_id, pergunta_var_id)\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "def upsert_rows(rows: List[Tuple]):\n",
    "    \"\"\"\n",
    "    rows should be tuples in order:\n",
    "    (pergunta_id, pergunta_var_id, pergunta, resposta, ultima_atualizacao, embedding_st_literal)\n",
    "    \"\"\"\n",
    "    sql = f\"\"\"\n",
    "        INSERT INTO {SCHEMA_NAME}.{TABLE_NAME}\n",
    "        (pergunta_id, pergunta_var_id, pergunta, resposta, ultima_atualizacao, embedding_st)\n",
    "        VALUES %s\n",
    "        ON CONFLICT (pergunta_id, pergunta_var_id) DO UPDATE\n",
    "        SET\n",
    "            pergunta = EXCLUDED.pergunta,\n",
    "            resposta = EXCLUDED.resposta,\n",
    "            ultima_atualizacao = EXCLUDED.ultima_atualizacao,\n",
    "            embedding_st = EXCLUDED.embedding_st;\n",
    "    \"\"\"\n",
    "    execute_values(cursor, sql, rows, page_size=DB_BATCH_SIZE)\n",
    "\n",
    "def to_pgvector_literal(vec: List[float]) -> str:\n",
    "    # pgvector accepts '[v1,v2,...]' literal\n",
    "    return \"[\" + \",\".join(f\"{float(x):.8f}\" for x in vec) + \"]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc6d857-2b06-4933-9c11-0e0a468c6704",
   "metadata": {},
   "source": [
    "# Main call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c9405b64-b7da-4155-9306-b706894f43fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1) Load Excel\n",
    "# -----------------------------\n",
    "\n",
    "# Expecting columns: pergunta_id, pergunta_var_id, pergunta, resposta, ultima_atualizacao\n",
    "# If your Excel has different names, rename here:\n",
    "df = pd.read_excel(EXCEL_PATH, sheet_name=SHEET_NAME)\n",
    "\n",
    "EXPECTED =  [\"pergunta_id\", \"pergunta_var_id\", \"pergunta\", \"resposta\", \"ultima_atualizacao\"]\n",
    "\n",
    "missing = [c for c in EXPECTED if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing expected columns in Excel: {missing}\")\n",
    "\n",
    "# Clean up types\n",
    "df[\"pergunta_id\"] = pd.to_numeric(df[\"pergunta_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df[\"pergunta_var_id\"] = pd.to_numeric(df[\"pergunta_var_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df[\"pergunta\"] = df[\"pergunta\"].fillna(\"\").astype(str)\n",
    "df[\"resposta\"] = df[\"resposta\"].fillna(\"\").astype(str)\n",
    "\n",
    "# ultima_atualizacao: try to parse to datetime; allow NaT\n",
    "if \"ultima_atualizacao\" in df.columns:\n",
    "    df[\"ultima_atualizacao\"] = pd.to_datetime(df[\"ultima_atualizacao\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows without pergunta text or without IDs\n",
    "df = df.dropna(subset=[\"pergunta_id\", \"pergunta_var_id\"])\n",
    "df = df[df[\"pergunta\"].str.strip() != \"\"].copy()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "if df.empty:\n",
    "    raise ValueError(\"No valid rows to process after cleaning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "52701e62-920d-4c7a-949d-9e79838c2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2) Get embeddings (one-by-one)\n",
    "# -----------------------------\n",
    "session = requests.Session()\n",
    "\n",
    "# First embedding to learn the dimensionality\n",
    "first_text = df.loc[0, \"pergunta\"]\n",
    "first_emb = fetch_embedding(first_text, session=session)\n",
    "embedding_dim = len(first_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6090f239-fa6e-4cd2-8b56-bcdddff50176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Ensure table with the correct dimension\n",
    "ensure_pgvector_extension_and_table(embedding_dim)\n",
    "\n",
    "rows_buffer: List[Tuple] = []\n",
    "\n",
    "# Add first row\n",
    "rows_buffer.append((\n",
    "    int(df.loc[0, \"pergunta_id\"]),\n",
    "    int(df.loc[0, \"pergunta_var_id\"]),\n",
    "    df.loc[0, \"pergunta\"],\n",
    "    df.loc[0, \"resposta\"],\n",
    "    df.loc[0, \"ultima_atualizacao\"].to_pydatetime() if pd.notnull(df.loc[0, \"ultima_atualizacao\"]) else None,\n",
    "    to_pgvector_literal(first_emb)\n",
    "))\n",
    "\n",
    "# Remaining rows\n",
    "for idx in range(1, len(df)):\n",
    "    text = df.loc[idx, \"pergunta\"]\n",
    "    emb = fetch_embedding(text, session=session)\n",
    "    if len(emb) != embedding_dim:\n",
    "        raise RuntimeError(\n",
    "            f\"Inconsistent embedding dimension at row {idx}: \"\n",
    "            f\"expected {embedding_dim}, got {len(emb)}\"\n",
    "        )\n",
    "    rows_buffer.append((\n",
    "        int(df.loc[idx, \"pergunta_id\"]),\n",
    "        int(df.loc[idx, \"pergunta_var_id\"]),\n",
    "        df.loc[idx, \"pergunta\"],\n",
    "        df.loc[idx, \"resposta\"],\n",
    "        df.loc[idx, \"ultima_atualizacao\"].to_pydatetime() if pd.notnull(df.loc[idx, \"ultima_atualizacao\"]) else None,\n",
    "        to_pgvector_literal(emb)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7b0fd269-776b-4d66-b03c-3ca3d6a0801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted/updated 25 rows into nlp.faq_embeddings with embedding dimension 384.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4) Upsert into Postgres (batched)\n",
    "# -----------------------------\n",
    "\n",
    "for i in range(0, len(rows_buffer), DB_BATCH_SIZE):\n",
    "    upsert_rows(rows_buffer[i:i+DB_BATCH_SIZE])\n",
    "\n",
    "print(f\"Inserted/updated {len(rows_buffer)} rows into {SCHEMA_NAME}.{TABLE_NAME} with embedding dimension {embedding_dim}.\")\n",
    "\n",
    "# Optional: create vector index after load (uncomment if desired)\n",
    "\n",
    "cursor.execute(f\"CREATE INDEX IF NOT EXISTS idx_faq_embeddings_hnsw ON {SCHEMA_NAME}.{TABLE_NAME} USING hnsw (embedding_st vector_l2_ops);\")\n",
    "cursor.execute(f\"ANALYZE {SCHEMA_NAME}.{TABLE_NAME};\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
